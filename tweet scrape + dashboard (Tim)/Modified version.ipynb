{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0b3bc14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timmo\\AppData\\Local\\Temp\\ipykernel_20984\\1491053780.py:28: FutureWarning: content is deprecated, use rawContent instead\n",
      "  attributes_container.append([tweet.date, tweet.likeCount, tweet.sourceLabel, country, tweet.user.username, tweet.user.followersCount, tweet.content])\n"
     ]
    }
   ],
   "source": [
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas as pd\n",
    "\n",
    "# hazard types and keywords to scrape tweets for\n",
    "hazard_types = [\"Blizzard\", \"Sea level rise\", \"Flood\", \"Heatwave\"]\n",
    "hazard_keywords = {\"Blizzard\":[\"snowstorm\", \"freezing\"],\n",
    "                   \"Sea level rise\": [],\n",
    "                   \"Flood\": [\"flooding\", \"river flood\", \"urban flood\"],\n",
    "                   \"Heatwave\": [\"heatwave\", \"heat stroke\", \"heat exhaustion\"]\n",
    "                  }\n",
    "\n",
    "#\"beach\", \"global warming\"\n",
    "# Using TwitterSearchScraper to scrape data and append tweets to list\n",
    "def TWTRScrapr(hazard_types):\n",
    "    tweets_df_list = [] # list to hold the dataframe for each hazard type\n",
    "    negation_keywords = \" -game -movie \"\n",
    "    for hazard_type in hazard_types:\n",
    "        keywords = ' '.join(hazard_keywords[hazard_type])\n",
    "        # Created a list to append all tweet attributes(data)\n",
    "        attributes_container = []\n",
    "        for i, tweet in enumerate(sntwitter.TwitterSearchScraper(f'{hazard_type} lang:en {keywords} {negation_keywords} -filter:retweets -filter:replies ').get_items()):\n",
    "            if i > 199: # limit to 200 tweets\n",
    "                break\n",
    "            if tweet.place:\n",
    "                country = tweet.place.country\n",
    "            else:\n",
    "                country = None\n",
    "            attributes_container.append([tweet.date, tweet.likeCount, tweet.sourceLabel, country, tweet.user.username, tweet.user.followersCount, tweet.content])\n",
    "        # Creating a dataframe from the tweets list above \n",
    "        tweets_df = pd.DataFrame(attributes_container, columns=[\"Date Created\", \"Number of Likes\", \"Source of Tweet\", \"Country\", \"Username\", \"Followers Count\", \"Tweets\"])\n",
    "        tweets_df_list.append(tweets_df.sort_values(by=['Date Created'], ascending = False).reset_index(drop=True))\n",
    "    return tweets_df_list\n",
    "\n",
    "#This is a list containing 4 dataframes, tweets_df_list[0] for blizzard tweets, tweets_df_list[1] for sea level rise tweets, etc.\n",
    "tweets_df_list = TWTRScrapr(hazard_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c400165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date Created</th>\n",
       "      <th>Number of Likes</th>\n",
       "      <th>Source of Tweet</th>\n",
       "      <th>Country</th>\n",
       "      <th>Username</th>\n",
       "      <th>Followers Count</th>\n",
       "      <th>Tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-03-01 11:14:16+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>dlvr.it</td>\n",
       "      <td>None</td>\n",
       "      <td>JeromeOLLIER</td>\n",
       "      <td>788</td>\n",
       "      <td>Actus Mer/Sea News:  Assessment of future floo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-03-01 11:02:38+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Greenland_SLR</td>\n",
       "      <td>None</td>\n",
       "      <td>cryo_data</td>\n",
       "      <td>137</td>\n",
       "      <td>Sea level rise (#SLR: üìà=üåä+üßäüíß) from üá¨üá±Greenland...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-03-01 10:07:04+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>None</td>\n",
       "      <td>kobiah</td>\n",
       "      <td>2113</td>\n",
       "      <td>Warmer temperatures, sea level rise and extrem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-03-01 09:39:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Sprout Social</td>\n",
       "      <td>None</td>\n",
       "      <td>WWF_Arctic</td>\n",
       "      <td>14522</td>\n",
       "      <td>If the outlet glaciers of #Greenland‚Äôs ice she...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-03-01 08:50:17+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>None</td>\n",
       "      <td>JeffMNeale</td>\n",
       "      <td>2295</td>\n",
       "      <td>A prediction of Europe in 2100, after anticipa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>2023-02-24 18:43:34+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>None</td>\n",
       "      <td>scicommlab</td>\n",
       "      <td>13942</td>\n",
       "      <td>Bay Area folks! Check out this FREE @swissnexS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>2023-02-24 18:27:32+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>None</td>\n",
       "      <td>madmilker</td>\n",
       "      <td>7927</td>\n",
       "      <td>Florida's Projected Sea Level Rise by 2100 Is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>2023-02-24 18:03:04+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>Hootsuite Inc.</td>\n",
       "      <td>None</td>\n",
       "      <td>Earth911</td>\n",
       "      <td>72231</td>\n",
       "      <td>In this podcast, we hear from Oceanographer Jo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>2023-02-24 18:00:16+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Sprout Social</td>\n",
       "      <td>None</td>\n",
       "      <td>LexisNexis</td>\n",
       "      <td>59653</td>\n",
       "      <td>This #ClimateChange special edition of the Lex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>2023-02-24 18:00:05+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Sharpspring</td>\n",
       "      <td>None</td>\n",
       "      <td>ResearchAether</td>\n",
       "      <td>247</td>\n",
       "      <td>Within all the research looking at climate cha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Date Created  Number of Likes      Source of Tweet Country  \\\n",
       "0   2023-03-01 11:14:16+00:00                0              dlvr.it    None   \n",
       "1   2023-03-01 11:02:38+00:00                0        Greenland_SLR    None   \n",
       "2   2023-03-01 10:07:04+00:00                0  Twitter for Android    None   \n",
       "3   2023-03-01 09:39:00+00:00                0        Sprout Social    None   \n",
       "4   2023-03-01 08:50:17+00:00                0  Twitter for Android    None   \n",
       "..                        ...              ...                  ...     ...   \n",
       "195 2023-02-24 18:43:34+00:00                1      Twitter Web App    None   \n",
       "196 2023-02-24 18:27:32+00:00                0      Twitter Web App    None   \n",
       "197 2023-02-24 18:03:04+00:00                1       Hootsuite Inc.    None   \n",
       "198 2023-02-24 18:00:16+00:00                0        Sprout Social    None   \n",
       "199 2023-02-24 18:00:05+00:00                0          Sharpspring    None   \n",
       "\n",
       "           Username  Followers Count  \\\n",
       "0      JeromeOLLIER              788   \n",
       "1         cryo_data              137   \n",
       "2            kobiah             2113   \n",
       "3        WWF_Arctic            14522   \n",
       "4        JeffMNeale             2295   \n",
       "..              ...              ...   \n",
       "195      scicommlab            13942   \n",
       "196       madmilker             7927   \n",
       "197        Earth911            72231   \n",
       "198      LexisNexis            59653   \n",
       "199  ResearchAether              247   \n",
       "\n",
       "                                                Tweets  \n",
       "0    Actus Mer/Sea News:  Assessment of future floo...  \n",
       "1    Sea level rise (#SLR: üìà=üåä+üßäüíß) from üá¨üá±Greenland...  \n",
       "2    Warmer temperatures, sea level rise and extrem...  \n",
       "3    If the outlet glaciers of #Greenland‚Äôs ice she...  \n",
       "4    A prediction of Europe in 2100, after anticipa...  \n",
       "..                                                 ...  \n",
       "195  Bay Area folks! Check out this FREE @swissnexS...  \n",
       "196  Florida's Projected Sea Level Rise by 2100 Is ...  \n",
       "197  In this podcast, we hear from Oceanographer Jo...  \n",
       "198  This #ClimateChange special edition of the Lex...  \n",
       "199  Within all the research looking at climate cha...  \n",
       "\n",
       "[200 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28bcdae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\timmo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "\n",
    "# Download stopwords if necessary\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load the stopwords\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "# Define a function to clean the text\n",
    "def clean_text(text):\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    # Remove emoji\n",
    "    text = re.sub('[^\\x00-\\x7F]+', ' ', text)\n",
    "    # Replace hyphens with spaces\n",
    "    text = re.sub('-', ' ', text)\n",
    "    # Remove punctuation marks and other unwanted characters\n",
    "    text = re.sub('[^a-zA-Z0-9\\s]', ' ', text)\n",
    "    # Remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    # Remove extra spaces\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Split into words\n",
    "    words = text.split()\n",
    "    # Remove stop words\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    # Join the words back into a string\n",
    "    cleaned_text = ' '.join(words)\n",
    "    return cleaned_text\n",
    "\n",
    "# Apply the clean_text function to the Tweets column\n",
    "for df in tweets_df_list:\n",
    "    df['Cleaned Tweets'] = df['Tweets'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc9d3a56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date Created</th>\n",
       "      <th>Number of Likes</th>\n",
       "      <th>Source of Tweet</th>\n",
       "      <th>Country</th>\n",
       "      <th>Username</th>\n",
       "      <th>Followers Count</th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Cleaned Tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-02-27 22:36:41+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>None</td>\n",
       "      <td>rvpstudioscana1</td>\n",
       "      <td>77</td>\n",
       "      <td>Don't y'all wish you were in Florida right now...</td>\n",
       "      <td>wish florida right eh major snow storm freezin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-02-25 13:42:18+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>None</td>\n",
       "      <td>BegreenKay</td>\n",
       "      <td>78</td>\n",
       "      <td>‚ÄúStrongest snowstorm in years‚Äù leaves Californ...</td>\n",
       "      <td>strongest snowstorm years leaves californians ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-02-23 18:42:58+00:00</td>\n",
       "      <td>22</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>None</td>\n",
       "      <td>MissBrandyGreen</td>\n",
       "      <td>3564</td>\n",
       "      <td>Took me 45 mins to #snowblow most of the drive...</td>\n",
       "      <td>took mins snowblow driveway amp main part fron...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-02-03 07:29:33+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Tumblr</td>\n",
       "      <td>None</td>\n",
       "      <td>Enfieldfinearts</td>\n",
       "      <td>1893</td>\n",
       "      <td>üìπ Intense Snowstorm in a Mountain Village‚îáSnow...</td>\n",
       "      <td>intense snowstorm mountain village snow ambien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-26 10:20:25+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>None</td>\n",
       "      <td>StormCentar</td>\n",
       "      <td>274</td>\n",
       "      <td>what happens !! 20 degrees below zero! Incredi...</td>\n",
       "      <td>happens degrees zero incredible snow disaster ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Date Created  Number of Likes      Source of Tweet Country  \\\n",
       "0 2023-02-27 22:36:41+00:00                2      Twitter Web App    None   \n",
       "1 2023-02-25 13:42:18+00:00                0   Twitter for iPhone    None   \n",
       "2 2023-02-23 18:42:58+00:00               22  Twitter for Android    None   \n",
       "3 2023-02-03 07:29:33+00:00                0               Tumblr    None   \n",
       "4 2023-01-26 10:20:25+00:00                2      Twitter Web App    None   \n",
       "\n",
       "          Username  Followers Count  \\\n",
       "0  rvpstudioscana1               77   \n",
       "1       BegreenKay               78   \n",
       "2  MissBrandyGreen             3564   \n",
       "3  Enfieldfinearts             1893   \n",
       "4      StormCentar              274   \n",
       "\n",
       "                                              Tweets  \\\n",
       "0  Don't y'all wish you were in Florida right now...   \n",
       "1  ‚ÄúStrongest snowstorm in years‚Äù leaves Californ...   \n",
       "2  Took me 45 mins to #snowblow most of the drive...   \n",
       "3  üìπ Intense Snowstorm in a Mountain Village‚îáSnow...   \n",
       "4  what happens !! 20 degrees below zero! Incredi...   \n",
       "\n",
       "                                      Cleaned Tweets  \n",
       "0  wish florida right eh major snow storm freezin...  \n",
       "1  strongest snowstorm years leaves californians ...  \n",
       "2  took mins snowblow driveway amp main part fron...  \n",
       "3  intense snowstorm mountain village snow ambien...  \n",
       "4  happens degrees zero incredible snow disaster ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df_list[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdd22da9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sentiment Analysis\n",
    "from textblob import TextBlob\n",
    "\n",
    "def fetch_sentiment_using_textblob(text):\n",
    "    analysis = TextBlob(text)\n",
    "    return 'pos' if analysis.sentiment.polarity >= 0 else 'neg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21cba47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying the function to get sentiment\n",
    "for df in tweets_df_list:\n",
    "    df['Sentiment'] = df['Cleaned Tweets'].apply(fetch_sentiment_using_textblob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c445fec",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date Created</th>\n",
       "      <th>Number of Likes</th>\n",
       "      <th>Source of Tweet</th>\n",
       "      <th>Country</th>\n",
       "      <th>Username</th>\n",
       "      <th>Followers Count</th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Cleaned Tweets</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-02-27 22:36:41+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>None</td>\n",
       "      <td>rvpstudioscana1</td>\n",
       "      <td>77</td>\n",
       "      <td>Don't y'all wish you were in Florida right now...</td>\n",
       "      <td>wish florida right eh major snow storm freezin...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-02-25 13:42:18+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>None</td>\n",
       "      <td>BegreenKay</td>\n",
       "      <td>78</td>\n",
       "      <td>‚ÄúStrongest snowstorm in years‚Äù leaves Californ...</td>\n",
       "      <td>strongest snowstorm years leaves californians ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-02-23 18:42:58+00:00</td>\n",
       "      <td>22</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>None</td>\n",
       "      <td>MissBrandyGreen</td>\n",
       "      <td>3564</td>\n",
       "      <td>Took me 45 mins to #snowblow most of the drive...</td>\n",
       "      <td>took mins snowblow driveway amp main part fron...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-02-03 07:29:33+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Tumblr</td>\n",
       "      <td>None</td>\n",
       "      <td>Enfieldfinearts</td>\n",
       "      <td>1893</td>\n",
       "      <td>üìπ Intense Snowstorm in a Mountain Village‚îáSnow...</td>\n",
       "      <td>intense snowstorm mountain village snow ambien...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-26 10:20:25+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>None</td>\n",
       "      <td>StormCentar</td>\n",
       "      <td>274</td>\n",
       "      <td>what happens !! 20 degrees below zero! Incredi...</td>\n",
       "      <td>happens degrees zero incredible snow disaster ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>2018-02-05 11:21:01+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>None</td>\n",
       "      <td>nlitenmebabe</td>\n",
       "      <td>1546</td>\n",
       "      <td>Snowfall of the century: Record-breaking snow ...</td>\n",
       "      <td>snowfall century record breaking snow freezing...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>2018-02-04 16:38:07+00:00</td>\n",
       "      <td>7</td>\n",
       "      <td>dlvr.it</td>\n",
       "      <td>None</td>\n",
       "      <td>TheWatchers_</td>\n",
       "      <td>13739</td>\n",
       "      <td>Snowfall of the century: Record-breaking snow ...</td>\n",
       "      <td>snowfall century record breaking snow freezing...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>2018-01-19 00:04:47+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>None</td>\n",
       "      <td>VeeBee123</td>\n",
       "      <td>422</td>\n",
       "      <td>*20-below-zero temps for two weeks, batshit cr...</td>\n",
       "      <td>zero temps two weeks batshit crazy bomb cyclon...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>2018-01-16 23:13:24+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>None</td>\n",
       "      <td>rebecca_star_04</td>\n",
       "      <td>30</td>\n",
       "      <td>Happy Winter Days‚ùÑÔ∏è #winter #snow #ice #Januar...</td>\n",
       "      <td>happy winter days winter snow ice january cold...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>2018-01-12 19:13:12+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>None</td>\n",
       "      <td>taschekats</td>\n",
       "      <td>1332</td>\n",
       "      <td>We just went from 11C overnight to freezing ra...</td>\n",
       "      <td>went c overnight freezing rain major blizzard ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows √ó 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Date Created  Number of Likes      Source of Tweet Country  \\\n",
       "0   2023-02-27 22:36:41+00:00                2      Twitter Web App    None   \n",
       "1   2023-02-25 13:42:18+00:00                0   Twitter for iPhone    None   \n",
       "2   2023-02-23 18:42:58+00:00               22  Twitter for Android    None   \n",
       "3   2023-02-03 07:29:33+00:00                0               Tumblr    None   \n",
       "4   2023-01-26 10:20:25+00:00                2      Twitter Web App    None   \n",
       "..                        ...              ...                  ...     ...   \n",
       "195 2018-02-05 11:21:01+00:00                0  Twitter for Android    None   \n",
       "196 2018-02-04 16:38:07+00:00                7              dlvr.it    None   \n",
       "197 2018-01-19 00:04:47+00:00                1   Twitter for iPhone    None   \n",
       "198 2018-01-16 23:13:24+00:00                1   Twitter for iPhone    None   \n",
       "199 2018-01-12 19:13:12+00:00                0   Twitter Web Client    None   \n",
       "\n",
       "            Username  Followers Count  \\\n",
       "0    rvpstudioscana1               77   \n",
       "1         BegreenKay               78   \n",
       "2    MissBrandyGreen             3564   \n",
       "3    Enfieldfinearts             1893   \n",
       "4        StormCentar              274   \n",
       "..               ...              ...   \n",
       "195     nlitenmebabe             1546   \n",
       "196     TheWatchers_            13739   \n",
       "197        VeeBee123              422   \n",
       "198  rebecca_star_04               30   \n",
       "199       taschekats             1332   \n",
       "\n",
       "                                                Tweets  \\\n",
       "0    Don't y'all wish you were in Florida right now...   \n",
       "1    ‚ÄúStrongest snowstorm in years‚Äù leaves Californ...   \n",
       "2    Took me 45 mins to #snowblow most of the drive...   \n",
       "3    üìπ Intense Snowstorm in a Mountain Village‚îáSnow...   \n",
       "4    what happens !! 20 degrees below zero! Incredi...   \n",
       "..                                                 ...   \n",
       "195  Snowfall of the century: Record-breaking snow ...   \n",
       "196  Snowfall of the century: Record-breaking snow ...   \n",
       "197  *20-below-zero temps for two weeks, batshit cr...   \n",
       "198  Happy Winter Days‚ùÑÔ∏è #winter #snow #ice #Januar...   \n",
       "199  We just went from 11C overnight to freezing ra...   \n",
       "\n",
       "                                        Cleaned Tweets Sentiment  \n",
       "0    wish florida right eh major snow storm freezin...       pos  \n",
       "1    strongest snowstorm years leaves californians ...       pos  \n",
       "2    took mins snowblow driveway amp main part fron...       pos  \n",
       "3    intense snowstorm mountain village snow ambien...       pos  \n",
       "4    happens degrees zero incredible snow disaster ...       pos  \n",
       "..                                                 ...       ...  \n",
       "195  snowfall century record breaking snow freezing...       pos  \n",
       "196  snowfall century record breaking snow freezing...       pos  \n",
       "197  zero temps two weeks batshit crazy bomb cyclon...       neg  \n",
       "198  happy winter days winter snow ice january cold...       pos  \n",
       "199  went c overnight freezing rain major blizzard ...       pos  \n",
       "\n",
       "[200 rows x 9 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5148f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the maximum number of words in a tweet across all dataframes\n",
    "max_words = 0\n",
    "for tweets_df in tweets_df_list:\n",
    "    max_words = max(max_words, tweets_df['Cleaned Tweets'].apply(lambda x: len(x.split())).max())\n",
    "\n",
    "# Create new columns for each word for each dataframe\n",
    "for tweets_df in tweets_df_list:\n",
    "    for i in range(max_words):\n",
    "        tweets_df[f'Text Token {i+1}'] = tweets_df['Cleaned Tweets'].apply(lambda x: x.split()[i] if len(x.split()) > i else '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "173df30e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date Created</th>\n",
       "      <th>Number of Likes</th>\n",
       "      <th>Source of Tweet</th>\n",
       "      <th>Country</th>\n",
       "      <th>Username</th>\n",
       "      <th>Followers Count</th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Cleaned Tweets</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Text Token 1</th>\n",
       "      <th>...</th>\n",
       "      <th>Text Token 31</th>\n",
       "      <th>Text Token 32</th>\n",
       "      <th>Text Token 33</th>\n",
       "      <th>Text Token 34</th>\n",
       "      <th>Text Token 35</th>\n",
       "      <th>Text Token 36</th>\n",
       "      <th>Text Token 37</th>\n",
       "      <th>Text Token 38</th>\n",
       "      <th>Text Token 39</th>\n",
       "      <th>Text Token 40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-02-27 22:36:41+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>None</td>\n",
       "      <td>rvpstudioscana1</td>\n",
       "      <td>77</td>\n",
       "      <td>Don't y'all wish you were in Florida right now...</td>\n",
       "      <td>wish florida right eh major snow storm freezin...</td>\n",
       "      <td>pos</td>\n",
       "      <td>wish</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-02-25 13:42:18+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>None</td>\n",
       "      <td>BegreenKay</td>\n",
       "      <td>78</td>\n",
       "      <td>‚ÄúStrongest snowstorm in years‚Äù leaves Californ...</td>\n",
       "      <td>strongest snowstorm years leaves californians ...</td>\n",
       "      <td>pos</td>\n",
       "      <td>strongest</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-02-23 18:42:58+00:00</td>\n",
       "      <td>22</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>None</td>\n",
       "      <td>MissBrandyGreen</td>\n",
       "      <td>3564</td>\n",
       "      <td>Took me 45 mins to #snowblow most of the drive...</td>\n",
       "      <td>took mins snowblow driveway amp main part fron...</td>\n",
       "      <td>pos</td>\n",
       "      <td>took</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-02-03 07:29:33+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Tumblr</td>\n",
       "      <td>None</td>\n",
       "      <td>Enfieldfinearts</td>\n",
       "      <td>1893</td>\n",
       "      <td>üìπ Intense Snowstorm in a Mountain Village‚îáSnow...</td>\n",
       "      <td>intense snowstorm mountain village snow ambien...</td>\n",
       "      <td>pos</td>\n",
       "      <td>intense</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-26 10:20:25+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>None</td>\n",
       "      <td>StormCentar</td>\n",
       "      <td>274</td>\n",
       "      <td>what happens !! 20 degrees below zero! Incredi...</td>\n",
       "      <td>happens degrees zero incredible snow disaster ...</td>\n",
       "      <td>pos</td>\n",
       "      <td>happens</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Date Created  Number of Likes      Source of Tweet Country  \\\n",
       "0 2023-02-27 22:36:41+00:00                2      Twitter Web App    None   \n",
       "1 2023-02-25 13:42:18+00:00                0   Twitter for iPhone    None   \n",
       "2 2023-02-23 18:42:58+00:00               22  Twitter for Android    None   \n",
       "3 2023-02-03 07:29:33+00:00                0               Tumblr    None   \n",
       "4 2023-01-26 10:20:25+00:00                2      Twitter Web App    None   \n",
       "\n",
       "          Username  Followers Count  \\\n",
       "0  rvpstudioscana1               77   \n",
       "1       BegreenKay               78   \n",
       "2  MissBrandyGreen             3564   \n",
       "3  Enfieldfinearts             1893   \n",
       "4      StormCentar              274   \n",
       "\n",
       "                                              Tweets  \\\n",
       "0  Don't y'all wish you were in Florida right now...   \n",
       "1  ‚ÄúStrongest snowstorm in years‚Äù leaves Californ...   \n",
       "2  Took me 45 mins to #snowblow most of the drive...   \n",
       "3  üìπ Intense Snowstorm in a Mountain Village‚îáSnow...   \n",
       "4  what happens !! 20 degrees below zero! Incredi...   \n",
       "\n",
       "                                      Cleaned Tweets Sentiment Text Token 1  \\\n",
       "0  wish florida right eh major snow storm freezin...       pos         wish   \n",
       "1  strongest snowstorm years leaves californians ...       pos    strongest   \n",
       "2  took mins snowblow driveway amp main part fron...       pos         took   \n",
       "3  intense snowstorm mountain village snow ambien...       pos      intense   \n",
       "4  happens degrees zero incredible snow disaster ...       pos      happens   \n",
       "\n",
       "   ... Text Token 31 Text Token 32 Text Token 33 Text Token 34 Text Token 35  \\\n",
       "0  ...                                                                         \n",
       "1  ...                                                                         \n",
       "2  ...                                                                         \n",
       "3  ...                                                                         \n",
       "4  ...                                                                         \n",
       "\n",
       "  Text Token 36 Text Token 37 Text Token 38 Text Token 39 Text Token 40  \n",
       "0                                                                        \n",
       "1                                                                        \n",
       "2                                                                        \n",
       "3                                                                        \n",
       "4                                                                        \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df_list[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1cbb90",
   "metadata": {},
   "source": [
    "# <u>Part 2</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b4d9775",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# List of countries\n",
    "countries = ['United States', 'China', 'India', 'Indonesia', 'Brazil', 'Pakistan', 'Bangladesh', \n",
    "             'Japan', 'Philippines', 'Vietnam', 'Turkey', 'Iran', 'Thailand', 'Myanmar', 'South Korea', \n",
    "             'Iraq', 'Afghanistan', 'Saudi Arabia', 'Malaysia', 'North Korea', 'Yemen', 'Nepal', \n",
    "             'North Macedonia', 'Kazakhstan', 'Syria', 'Jordan', 'Azerbaijan', 'United Arab Emirates', \n",
    "             'Tajikistan', 'Israel', 'Laos', 'Lebanon', 'Kyrgyzstan', 'Turkmenistan', 'Oman', 'State of Palestine', \n",
    "             'Kuwait', 'Georgia', 'Armenia', 'Bahrain', 'Cyprus', 'Mongolia', 'Qatar', 'Timor-Leste', \n",
    "             'Bahamas', 'Bhutan', 'Maldives', 'Iceland', 'Brunei']\n",
    "\n",
    "# Function to randomly assign a country to a row\n",
    "def random_country(row):\n",
    "    if row['Country'] == None:\n",
    "        return np.random.choice(countries)\n",
    "    else:\n",
    "        return row['Country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31a0f9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to the dataframe\n",
    "for df in tweets_df_list:\n",
    "    df['Country'] = df.apply(random_country, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c04d631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty dataframe to store the merged data\n",
    "merged_df = pd.DataFrame()\n",
    "\n",
    "# Iterate over each dataframe in tweets_df_list\n",
    "for i in range(len(tweets_df_list)):\n",
    "    # Add a column to each dataframe to indicate the type\n",
    "    tweets_df_list[i]['Type'] = hazard_types[i]\n",
    "    # Append the dataframe to the merged_df\n",
    "    merged_df = merged_df.append(tweets_df_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3365f04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv(\"Tweets2.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
